Usage instructions:
	1. type "make" or "make all"
	2. Run using "./tigerc <file_name>
	
	OR
	1. type "make"
	2. python test_runner.py #to run the entire test suite and give categorized output

Using make should recompile the compiler and the associated grammar.

I precompiled goyacc and included it within tools folder and the makefile uses it as well.
I included goyaccs source code in the vendor folder as well.

External Dependencies: (Mostly for links, you shouldnt have to install these!)
	Lexical analysis framework for Go - github.com/timtadh/lexmachine

Design Decisions:
	Ultimately, I should have
	scrapped all of the code once I realized it's major flaws, but I had spent
	so much time getting to where I was that I couldn't justify letting go,
	once it grew into this massive mess, I felt that I had to commit to this
	monstrosity that I created. I also believe using go in this way was also a bit tough for me.
	I've used go in many of my own personal projects but never the way I used it
	in this project. So I ran into entirely new issues, and then embedded
	over the top solutions for things that could've been simpler if done
	in an idiomatic go way, rather than twisting go to perform like
	something it was not. I understood the project and material however,
	some way through, it felt like I was fighting the code
	base not designing it, and this eventually maimed the project and its ability
	to be augmented.
	In retrospect, I should have ripped the code base to shreds and redesigned
	bottom up. However, letting go is tough and failure is crucial for progress.
	Ultimately, I learned a lot about go, a lot about myself,
	and a ton about lexing, semantics, type checking, and interpretation.


	ACTUAL DESIGN DECISIONS: -> If you read the massive block of text, the design
	choices are a mess. Semantically, I thought I did some clever programming by
	using recursion to resolve types which did work almost flawlessly. However,
	I could not figure out a way to conceptualize type checking arrays and recursive types
	and records with this design, so the array/rectype is only MINIMALLY functional.
	If a type references another complex type like an array in its declaration,
	it is basically resolved to a catch all "recType" rather than its actual type.
	For arrays, they are resolved to their most primitive types usually ints or strings.
	Both of these are inaccurate ways of semantically checking but I figured I would come back
	and fix this, I never did :(. Ultimately, that recursive resolution of types became
	ambiguous as I overused the function and designed it to do more than it should have. Which
	ambiguated it's use and eventually it's return type, which rippled across the code base
	to probably maybe 20 or 30 type casts globally in the code base.
	For the symbol table and semantic analysis, I took some cues from the Crafting a Compiler
	link above and I modified it to be effective in my codebase however, I assumed
	that the table did more than it should have. In the end, I should have used 2 separate
	tables, which would have simplified this process by a ton. Before that point the symbol table implementation,
 	I believe was a great solution. It used a sort pseudo-stack like linked list to scope variables which I thought
	was very very cool. For the Interpreter, I thought it would be very cool to do something
	recursive like I did with the types and that worked awesome. I ended creating an evaluateExpression
	function which would take pretty much any tiger expression use a type switch, and then evaluate
	the value for the expression. The awesome part about it, is that it was a big brain function so it
	would evaluate all of the relevant surrounding expressions needed to evaluate the original expression.
	This made retrieving values for everything when interpreting the code very very easy and straight forward.
	If I could redesign from the bottom up, I would probably keep this design but I think my code only benefitted
	from this function due to the nature of it's bad design. Ultimately, it's a good function for an awful
	design.
	Lexically, I used the lexmachine library from github which is linked above. If I could back in time,
	I would handwrite it in a heartbeat, I needed more control for this project and although it fit my needs.
	It wouldn't have been that difficult to write my own implementation of one. The cryptic docoumentation
	of the repo and lack of examples had me reading more source code than actually using it.
	The Lexer doesn't catch unterminated comments, I tried to re work it for awhile to catch them but
	I resolved to pour that extra time into the other parts.
	
	All in all 10/10 learning experience, I'm much better at Go and made a compiler, pogchamp.
